# Documentaci√≥n T√©cnica del Backend - Sistema de Detecci√≥n de Posturas

## √çndice de Contenidos

1. [Introducci√≥n](#introducci√≥n)
2. [Arquitectura General del Sistema](#arquitectura-general-del-sistema)
3. [Tecnolog√≠as y Dependencias](#tecnolog√≠as-y-dependencias)
4. [Estructura del Proyecto](#estructura-del-proyecto)
5. [M√≥dulo Principal (main.py)](#m√≥dulo-principal-mainpy)
6. [Monitor de Posturas (posture_monitor.py)](#monitor-de-posturas-posture_monitorpy)
7. [Capa de Datos](#capa-de-datos)
8. [API REST y Endpoints](#api-rest-y-endpoints)
9. [Sistema de Comunicaci√≥n en Tiempo Real](#sistema-de-comunicaci√≥n-en-tiempo-real)
10. [Integraci√≥n con OpenAI](#integraci√≥n-con-openai)
11. [Sistema de Cach√© con Redis](#sistema-de-cach√©-con-redis)
12. [Despliegue y Containerizaci√≥n](#despliegue-y-containerizaci√≥n)
13. [Flujo de Datos y Casos de Uso](#flujo-de-datos-y-casos-de-uso)
14. [An√°lisis de Fortalezas y Oportunidades de Mejora](#an√°lisis-de-fortalezas-y-oportunidades-de-mejora)
15. [Conclusiones](#conclusiones)

---

## Introducci√≥n

El presente documento describe la arquitectura e implementaci√≥n del backend de un sistema de detecci√≥n de posturas corporales en tiempo real. Este sistema forma parte de un proyecto de ingenier√≠a orientado a mejorar la salud postural mediante el an√°lisis autom√°tico de im√°genes y la generaci√≥n de alertas preventivas.

El backend est√° dise√±ado siguiendo principios de arquitectura de microservicios, implementando una API REST con FastAPI, procesamiento de video en tiempo real mediante WebSockets, an√°lisis de posturas con MediaPipe, y clasificaci√≥n avanzada mediante la API de OpenAI. La arquitectura permite la escalabilidad horizontal y el procesamiento concurrente de m√∫ltiples sesiones de usuarios.

### Objetivos del Sistema

1. **Procesamiento en tiempo real**: Analizar streams de video para detectar posturas corporales inadecuadas.
2. **Alertas inteligentes**: Generar notificaciones cuando se detectan posturas incorrectas sostenidas.
3. **An√°lisis mediante IA**: Utilizar modelos de visi√≥n por computadora para clasificaci√≥n detallada de posturas.
4. **Persistencia de datos**: Almacenar m√©tricas y estad√≠sticas para an√°lisis posterior.
5. **Integraci√≥n multiplataforma**: Soportar clientes web y bot de Telegram.

---

## Arquitectura General del Sistema

El backend implementa una arquitectura orientada a eventos con los siguientes componentes principales:

### Componentes Principales

1. **Servidor FastAPI**: N√∫cleo del sistema que expone la API REST y maneja conexiones WebSocket.
2. **Motor de Procesamiento de Video**: M√≥dulo especializado en an√°lisis de posturas usando MediaPipe.
3. **Sistema de Colas As√≠ncronas**: Gesti√≥n de tareas de procesamiento mediante colas en memoria.
4. **Base de Datos PostgreSQL**: Almacenamiento persistente de sesiones, pacientes y m√©tricas.
5. **Cache Redis**: Almacenamiento temporal de datos de sesi√≥n y m√©tricas en tiempo real.
6. **Worker de An√°lisis IA**: Proceso as√≠ncrono para clasificaci√≥n de posturas con OpenAI.

### Diagrama de Arquitectura

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê     ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê     ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ   Cliente Web   ‚îÇ     ‚îÇ  Bot Telegram    ‚îÇ     ‚îÇ Otros Clientes  ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò     ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò     ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
         ‚îÇ                       ‚îÇ                          ‚îÇ
         ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                                 ‚îÇ
                    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
                    ‚îÇ    FastAPI Backend      ‚îÇ
                    ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îÇ
                    ‚îÇ  ‚îÇ  WebSocket API  ‚îÇ    ‚îÇ
                    ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îÇ
                    ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îÇ
                    ‚îÇ  ‚îÇ    REST API     ‚îÇ    ‚îÇ
                    ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îÇ
                    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                                 ‚îÇ
        ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
        ‚îÇ                        ‚îÇ                        ‚îÇ
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê      ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê     ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ PostureMonitor ‚îÇ      ‚îÇ  Async Workers  ‚îÇ     ‚îÇ   API Routers   ‚îÇ
‚îÇ   (MediaPipe)  ‚îÇ      ‚îÇ  (OpenAI API)   ‚îÇ     ‚îÇ   (Endpoints)   ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò      ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò     ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
        ‚îÇ                        ‚îÇ                        ‚îÇ
        ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                                 ‚îÇ
                    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
                    ‚îÇ    Data Layer          ‚îÇ
                    ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê   ‚îÇ
                    ‚îÇ  ‚îÇ   PostgreSQL    ‚îÇ   ‚îÇ
                    ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò   ‚îÇ
                    ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê   ‚îÇ
                    ‚îÇ  ‚îÇ     Redis       ‚îÇ   ‚îÇ
                    ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò   ‚îÇ
                    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

---

## Tecnolog√≠as y Dependencias

El proyecto utiliza un stack tecnol√≥gico moderno optimizado para procesamiento en tiempo real:

### Dependencias Principales

```python
# requirements.txt
opencv-python-headless    # Procesamiento de im√°genes sin GUI
websockets               # Comunicaci√≥n bidireccional en tiempo real
mediapipe               # Detecci√≥n de puntos clave corporales
numpy                   # Operaciones num√©ricas y matrices
fastapi                 # Framework web as√≠ncrono de alto rendimiento
uvicorn                 # Servidor ASGI para FastAPI
sqlalchemy              # ORM para base de datos
psycopg2-binary        # Driver PostgreSQL
redis                   # Sistema de cach√© en memoria
openai>=0.27.0         # API de OpenAI para an√°lisis con IA
requests               # Cliente HTTP para integraciones
```

### Justificaci√≥n Tecnol√≥gica

1. **FastAPI**: Elegido por su rendimiento superior, soporte nativo de async/await y generaci√≥n autom√°tica de documentaci√≥n OpenAPI.

2. **MediaPipe**: Soluci√≥n de Google para detecci√≥n de poses humanas con alta precisi√≥n y rendimiento optimizado.

3. **PostgreSQL + SQLAlchemy**: Combinaci√≥n robusta para persistencia de datos con soporte transaccional completo.

4. **Redis**: Cache de alta velocidad para datos temporales y comunicaci√≥n entre procesos.

5. **OpenAI GPT-4 Vision**: Modelo de IA avanzado para clasificaci√≥n detallada de posturas a partir de im√°genes.

---

## Estructura del Proyecto

La organizaci√≥n del c√≥digo sigue una estructura modular clara:

```
/workspace/
‚îú‚îÄ‚îÄ main.py                    # Punto de entrada principal
‚îú‚îÄ‚îÄ posture_monitor.py         # Motor de an√°lisis de posturas
‚îú‚îÄ‚îÄ requirements.txt           # Dependencias del proyecto
‚îú‚îÄ‚îÄ Dockerfile                 # Configuraci√≥n de contenedor
‚îú‚îÄ‚îÄ api/                       # M√≥dulo de API
‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îú‚îÄ‚îÄ database.py           # Configuraci√≥n de base de datos
‚îÇ   ‚îú‚îÄ‚îÄ models.py             # Modelos SQLAlchemy
‚îÇ   ‚îú‚îÄ‚îÄ schemas.py            # Esquemas Pydantic
‚îÇ   ‚îî‚îÄ‚îÄ routers/              # Endpoints organizados por dominio
‚îÇ       ‚îú‚îÄ‚îÄ analysis.py       # Endpoints de an√°lisis
‚îÇ       ‚îú‚îÄ‚îÄ calibracion.py    # Endpoints de calibraci√≥n
‚îÇ       ‚îú‚îÄ‚îÄ metricas.py       # Endpoints de m√©tricas
‚îÇ       ‚îú‚îÄ‚îÄ pacientes.py      # Endpoints de pacientes
‚îÇ       ‚îú‚îÄ‚îÄ postura_counts.py # Endpoints de conteo de posturas
‚îÇ       ‚îú‚îÄ‚îÄ sesiones.py       # Endpoints de sesiones
‚îÇ       ‚îî‚îÄ‚îÄ timeline.py       # Endpoints de l√≠nea temporal
‚îî‚îÄ‚îÄ deploy/                    # Configuraciones de despliegue
    ‚îú‚îÄ‚îÄ backend-svc.yaml      # Servicio Kubernetes backend
    ‚îú‚îÄ‚îÄ database-svc.yaml     # Servicio Kubernetes DB
    ‚îú‚îÄ‚îÄ redis-deploy.yaml     # Despliegue Redis
    ‚îî‚îÄ‚îÄ shpd-backend.yaml     # Despliegue principal
```

---

## M√≥dulo Principal (main.py)

El archivo `main.py` constituye el punto de entrada del backend y orquesta todos los componentes del sistema. A continuaci√≥n se detalla su implementaci√≥n:

### Importaciones y Configuraci√≥n Inicial

```python
import os
import asyncio
import logging
import json
import time
import cv2
import numpy as np
import redis
import base64
import logging.config
from contextlib import asynccontextmanager
from openai import OpenAI
from fastapi import FastAPI, WebSocket, WebSocketDisconnect
from fastapi.middleware.cors import CORSMiddleware
import uvicorn
```

Las importaciones se organizan en:
- **Librer√≠as est√°ndar**: `os`, `asyncio`, `logging`, `json`, `time`
- **Procesamiento de im√°genes**: `cv2` (OpenCV), `numpy`
- **Servicios externos**: `redis`, `openai`
- **Framework web**: `fastapi`, `uvicorn`
- **M√≥dulos locales**: Modelos, base de datos, monitores y routers

### Configuraci√≥n de Logging

El sistema implementa una configuraci√≥n detallada de logging para facilitar el debugging y monitoreo:

```python
LOGGING_CONFIG = {
    "version": 1,
    "disable_existing_loggers": False,
    "formatters": {
        "default": {
            "format": "%(asctime)s [%(levelname)s] %(name)s: %(message)s",
            "datefmt": "%Y-%m-%d %H:%M:%S"
        }
    },
    "handlers": {
        "console": {
            "class": "logging.StreamHandler",
            "formatter": "default",
            "level": "DEBUG",
            "stream": "ext://sys.stdout"
        }
    },
    "loggers": {
        "posture_monitor": {"handlers": ["console"], "level": "DEBUG"},
        "api_analysis_worker": {"handlers": ["console"], "level": "DEBUG"},
        "uvicorn.access": {"handlers": ["console"], "level": "WARNING"},
        "uvicorn.error": {"handlers": ["console"], "level": "WARNING"}
    },
    "root": {"handlers": ["console"], "level": "WARNING"}
}
```

Esta configuraci√≥n:
- Define un formato consistente para todos los logs
- Separa niveles de logging por m√≥dulo
- Filtra logs verbosos de uvicorn para reducir ruido

### Cliente de OpenAI

La integraci√≥n con OpenAI se configura mediante variables de entorno:

```python
API_KEY = os.getenv("OPENAI_API_KEY", "sk-proj-...")
client = OpenAI(api_key=API_KEY)
MODEL = "gpt-4o-mini"
```

### Funci√≥n de Construcci√≥n de Mensajes para OpenAI

Esta funci√≥n es cr√≠tica para el an√°lisis de posturas mediante IA:

```python
def build_openai_messages(b64: str) -> list[dict]:
    """
    Construye la lista de mensajes para enviar a la API de OpenAI GPT-4 Vision,
    solicitando porcentajes (0-100) que indiquen la predominancia de cada postura.
    """
    SYSTEM_PROMPT = """Eres un asistente de clasificaci√≥n de posturas basado en visi√≥n.
    Cuando recibas una imagen, analiza la postura de la persona 
    qu√© tan predominante es cada una de las siguientes 13 posturas al sentarse.
    Las posturas son:
    - Sentado erguido
    - Inclinaci√≥n hacia adelante
    - Inclinaci√≥n hacia atr√°s
    - Inclinaci√≥n hacia la izquierda
    - Inclinaci√≥n hacia la derecha
    - Ment√≥n en mano
    - Piernas cruzadas
    - Rodillas elevadas o muy bajas
    - Hombros encogidos
    - Brazos sin apoyo
    - Cabeza adelantada
    - Encorvarse hacia adelante
    - Sentarse en el borde del asiento
    """
```

La funci√≥n:
1. Define un prompt de sistema detallado con las 13 posturas a analizar
2. Construye el mensaje del usuario incluyendo la imagen en base64
3. Retorna la estructura de mensajes esperada por la API de OpenAI

### Sistema de Colas As√≠ncronas

El backend utiliza colas as√≠ncronas para gestionar el flujo de procesamiento:

```python
processed_frames_queue: asyncio.Queue = asyncio.Queue(maxsize=10)
api_analysis_queue: asyncio.Queue = asyncio.Queue()
_triggered_sessions = set()  # Control de disparos √∫nicos por sesi√≥n
```

- **processed_frames_queue**: Almacena frames procesados para transmisi√≥n
- **api_analysis_queue**: Cola de trabajos pendientes de an√°lisis con IA
- **_triggered_sessions**: Evita an√°lisis duplicados por sesi√≥n

### Worker de An√°lisis con IA

El worker as√≠ncrono consume tareas de an√°lisis:

```python
async def api_analysis_worker():
    """
    Worker que consume de api_analysis_queue payloads con:
      { session_id, b64, exercise }
    Llama a OpenAI y guarda el JSON resultante en Redis.
    """
    loop = asyncio.get_running_loop()
    logger.debug("üîÑ API analysis worker iniciado")
    
    while True:
        payload = await api_analysis_queue.get()
        session_id = payload["session_id"]
        jpeg = payload["jpeg"]
        bad_time = payload["bad_time"]
        b64 = base64.b64encode(jpeg).decode("utf-8")
        
        try:
            # Llamada a OpenAI en executor para no bloquear
            messages = build_openai_messages(b64)
            response = await loop.run_in_executor(
                None,
                lambda: client.chat.completions.create(
                    user=session_id,
                    model=MODEL,
                    messages=messages,
                    temperature=0,
                    max_tokens=500
                )
            )
```

Este worker:
1. Opera en un bucle infinito consumiendo tareas
2. Codifica im√°genes en base64
3. Ejecuta llamadas a OpenAI en un thread pool para no bloquear
4. Almacena resultados en Redis
5. Actualiza contadores de posturas en la base de datos
6. Registra eventos en la l√≠nea temporal

### Gesti√≥n del Ciclo de Vida de la Aplicaci√≥n

```python
@asynccontextmanager
async def lifespan(app: FastAPI):
    asyncio.create_task(api_analysis_worker())
    logger.debug("‚úÖ API analysis worker scheduled")
    yield
```

El gestor de contexto as√≠ncrono:
- Inicia el worker de an√°lisis al arrancar la aplicaci√≥n
- Garantiza limpieza ordenada al cerrar

### Configuraci√≥n de FastAPI y CORS

```python
app = FastAPI(lifespan=lifespan)
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)
```

La configuraci√≥n CORS permite:
- Acceso desde cualquier origen (desarrollo)
- Todos los m√©todos HTTP
- Todas las cabeceras
- Credenciales en peticiones

### Inclusi√≥n de Routers

```python
app.include_router(sesiones.router)
app.include_router(pacientes.router)
app.include_router(metricas.router)
app.include_router(analysis.router)
app.include_router(postura_counts.router)
app.include_router(timeline.router)
app.include_router(calibracion.router)
```

Los routers organizan los endpoints por dominio funcional.

### WebSocket de Entrada de Video

El endpoint m√°s complejo del sistema maneja el stream de video:

```python
@app.websocket("/video/input/{device_id}")
async def video_input(websocket: WebSocket, device_id: str):
    await websocket.accept()
    loop = asyncio.get_running_loop()
    
    # Detectar modo calibraci√≥n
    calibrating_query = websocket.scope.get("query_string", b"").decode().find("calibracion=1") >= 0
    
    # Variables de estado
    posture_monitor = None
    current_session_id = None
    
    try:
        while True:
            # 1. Verificar session_id desde Redis
            redis_shpd_key = f"shpd-data:{device_id}"
            session_id = r.hget(redis_shpd_key, "session_id")
            
            # 2. Determinar modo (calibraci√≥n o normal)
            mode = r.hget(redis_shpd_key, "mode")
            calibrating = (mode != "normal") if mode else calibrating_query
            
            # 3. Reinicializar PostureMonitor si cambi√≥ la sesi√≥n
            if session_id != current_session_id:
                posture_monitor = PostureMonitor(session_id, save_metrics=not calibrating)
                current_session_id = session_id
            
            # 4. Procesar frame
            data = await websocket.receive_bytes()
            frame = await loop.run_in_executor(None, _decode_jpeg, data)
            
            if posture_monitor:
                processed = await loop.run_in_executor(None, posture_monitor.process_frame, frame)
                jpeg = await loop.run_in_executor(None, _encode_jpeg, processed)
            
            # 5. Encolar frame procesado
            if processed_frames_queue.full():
                processed_frames_queue.get_nowait()
            await processed_frames_queue.put(jpeg)
            
            # 6. Disparar an√°lisis si hay alerta
            if posture_monitor and not calibrating:
                raw_key = f"raw_frame:{session_id}"
                if r.hget(raw_key, "flag_alert") == "1":
                    await api_analysis_queue.put({
                        "session_id": session_id,
                        "jpeg": jpeg,
                        "bad_time": r.hget(raw_key, "bad_time")
                    })
                    r.delete(raw_key)
```

Este endpoint:
1. Acepta conexiones WebSocket por dispositivo
2. Detecta y gestiona modos de operaci√≥n (calibraci√≥n/normal)
3. Mantiene un monitor de posturas por sesi√≥n
4. Procesa frames de manera as√≠ncrona
5. Gestiona la cola de frames procesados
6. Dispara an√°lisis con IA cuando se detectan alertas

### WebSocket de Salida de Video

```python
@app.websocket("/video/output")
async def video_output(websocket: WebSocket):
    await websocket.accept()
    try:
        while True:
            jpeg = await processed_frames_queue.get()
            await websocket.send_bytes(jpeg)
    except WebSocketDisconnect:
        pass
```

Este endpoint simple:
- Consume frames de la cola procesada
- Los transmite a clientes conectados
- Maneja desconexiones gracefully

### Funciones Auxiliares de Codificaci√≥n

```python
def _decode_jpeg(data: bytes):
    arr = np.frombuffer(data, np.uint8)
    return cv2.imdecode(arr, cv2.IMREAD_COLOR)

def _encode_jpeg(frame):
    _, buf = cv2.imencode('.jpg', frame, [cv2.IMWRITE_JPEG_QUALITY, 50])
    return buf.tobytes()
```

Estas funciones:
- Convierten entre bytes JPEG y arrays NumPy
- Aplican compresi√≥n JPEG con calidad 50 para optimizar ancho de banda

### Inicializaci√≥n y Arranque

```python
Base.metadata.create_all(bind=engine)

if __name__ == "__main__":
    uvicorn.run(
        app,
        host="0.0.0.0",
        port=8765,
        log_level="warning",
        access_log=True
    )
```

El servidor:
- Crea las tablas de base de datos si no existen
- Escucha en todas las interfaces en el puerto 8765
- Configura logging moderado para producci√≥n

---

## Monitor de Posturas (posture_monitor.py)

El m√≥dulo `posture_monitor.py` implementa el motor de an√°lisis de posturas utilizando MediaPipe. Este componente es fundamental para la detecci√≥n en tiempo real de posturas corporales incorrectas.

### Arquitectura del Monitor

```python
import cv2
import time
import math as m
import mediapipe as mp
import argparse
import json
import os
from datetime import datetime
from api.database import SessionLocal
from api.models import MetricaPostural
import logging
import redis
```

### Clase PostureMonitor

La clase principal encapsula toda la l√≥gica de detecci√≥n:

```python
class PostureMonitor:
    def __init__(self, session_id: str, *, save_metrics: bool = True):
        logger.info(f"[PostureMonitor] Instanciado para session_id={session_id} save_metrics={save_metrics}")
        self.mp_drawing = mp.solutions.drawing_utils
        self.session_id = session_id
        self.save_metrics = save_metrics
```

#### Par√°metros de Inicializaci√≥n

- **session_id**: Identificador √∫nico de la sesi√≥n de monitoreo
- **save_metrics**: Booleano que indica si se deben persistir las m√©tricas (False en modo calibraci√≥n)

#### Configuraci√≥n de MediaPipe

```python
self.mp_pose = mp.solutions.pose
self.pose = self.mp_pose.Pose(
    static_image_mode=False,
    min_detection_confidence=0.5,
    min_tracking_confidence=0.5
)
```

Los par√°metros de MediaPipe est√°n optimizados para:
- **static_image_mode=False**: Procesamiento de video continuo
- **min_detection_confidence=0.5**: Balance entre precisi√≥n y velocidad
- **min_tracking_confidence=0.5**: Seguimiento estable de puntos clave

### Sistema de Umbrales Configurables

El monitor carga umbrales desde un archivo JSON o usa valores por defecto:

```python
if os.path.exists("calibration.json"):
    with open("calibration.json", "r") as f:
        data = json.load(f)
        self.args.offset_threshold = data.get("offset_threshold", self.args.offset_threshold)
        self.args.neck_angle_threshold = data.get("neck_angle_threshold", self.args.neck_angle_threshold)
        self.args.torso_angle_threshold = data.get("torso_angle_threshold", self.args.torso_angle_threshold)
        self.args.time_threshold = data.get("time_threshold", self.args.time_threshold)
```

Los umbrales controlan:
- **offset_threshold**: Desalineaci√≥n de hombros (p√≠xeles)
- **neck_angle_threshold**: √Ångulo m√°ximo de inclinaci√≥n del cuello (grados)
- **torso_angle_threshold**: √Ångulo m√°ximo de inclinaci√≥n del torso (grados)
- **time_threshold**: Tiempo antes de generar alerta (segundos)

### Funciones Matem√°ticas de C√°lculo

#### C√°lculo de Distancia Euclidiana

```python
def findDistance(self, x1, y1, x2, y2):
    dist = m.sqrt((x2 - x1)**2 + (y2 - y1)**2)
    return dist
```

#### C√°lculo de √Ångulo de Inclinaci√≥n

```python
def findAngle(self, x1, y1, x2, y2):
    theta = m.acos((y2 - y1) * (-y1) / (m.sqrt((x2 - x1)**2 + (y2 - y1)**2) * y1))
    degree = int(180/m.pi) * theta
    return degree
```

Esta funci√≥n calcula el √°ngulo entre:
- Un vector formado por dos puntos corporales
- El eje vertical

La f√≥rmula utiliza el producto escalar normalizado para obtener el coseno del √°ngulo.

### Procesamiento de Frames

El m√©todo principal `process_frame` ejecuta el an√°lisis:

```python
def process_frame(self, image):
    h, w = image.shape[:2]
    image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
    keypoints = self.pose.process(image_rgb)
    image = cv2.cvtColor(image_rgb, cv2.COLOR_RGB2BGR)
```

#### Extracci√≥n de Puntos Clave

```python
lm = keypoints.pose_landmarks
lmPose = self.mp_pose.PoseLandmark

# Detecci√≥n de ausencia de persona
if lm is None:
    delta = 1.0 / fps
    r.hincrbyfloat(buffer_key, "tiempo_parado", round(delta,1))
    return image

# Puntos clave del lado derecho
r_shldr_x = int(lm.landmark[lmPose.RIGHT_SHOULDER].x * w)
r_shldr_y = int(lm.landmark[lmPose.RIGHT_SHOULDER].y * h)
r_ear_x = int(lm.landmark[lmPose.RIGHT_EAR].x * w)
r_ear_y = int(lm.landmark[lmPose.RIGHT_EAR].y * h)
r_hip_x = int(lm.landmark[lmPose.RIGHT_HIP].x * w)
r_hip_y = int(lm.landmark[lmPose.RIGHT_HIP].y * h)
```

El sistema:
1. Convierte coordenadas normalizadas a p√≠xeles
2. Extrae puntos del hombro, oreja y cadera derechos
3. Estos puntos definen la postura del usuario

#### C√°lculo de √Ångulos Posturales

```python
neck_inclination = self.findAngle(r_shldr_x, r_shldr_y, r_ear_x, r_ear_y)
torso_inclination = self.findAngle(r_hip_x, r_hip_y, r_shldr_x, r_shldr_y)
```

- **neck_inclination**: √Ångulo entre hombro-oreja y vertical (inclinaci√≥n de cabeza)
- **torso_inclination**: √Ångulo entre cadera-hombro y vertical (inclinaci√≥n de espalda)

### Evaluaci√≥n de Postura

```python
if neck_inclination < self.args.neck_angle_threshold and torso_inclination < self.args.torso_angle_threshold:
    # Postura correcta
    self.bad_frames = 0
    self.good_frames += 1
    color = (127, 233, 100)  # Verde
    r.hincrby(buffer_key, "good_frames", 1)
    self.flag_transition = True
    self.flag_alert = True
else:
    # Postura incorrecta
    self.good_frames = 0
    self.bad_frames += 1
    color = (50, 50, 255)   # Rojo
    r.hincrby(buffer_key, "bad_frames", 1)
    
    if self.flag_transition:
        r.hincrby(buffer_key, "transiciones_malas", 1)
        self.flag_transition = False
```

El sistema:
1. Compara √°ngulos con umbrales configurados
2. Mantiene contadores separados para frames buenos/malos
3. Detecta transiciones entre posturas
4. Actualiza estad√≠sticas en Redis en tiempo real

### Visualizaci√≥n y Feedback

```python
# Dibujar texto informativo
cv2.putText(image, angle_text_string_neck, (10, 30), self.font, 0.6, color, 2)
cv2.putText(image, angle_text_string_torso, (10, 60), self.font, 0.6, color, 2)

# Dibujar puntos clave
cv2.circle(image, (r_shldr_x, r_shldr_y), 7, (255, 255, 255), 2)
cv2.circle(image, (r_ear_x, r_ear_y), 7, (255, 255, 255), 2)
cv2.circle(image, (r_hip_x, r_hip_y), 7, (0, 255, 255), -1)

# Dibujar l√≠neas de referencia
cv2.line(image, (r_shldr_x, r_shldr_y), (r_ear_x, r_ear_y), color, 2)
cv2.line(image, (r_hip_x, r_hip_y), (r_shldr_x, r_shldr_y), color, 2)
```

La visualizaci√≥n incluye:
- Valores num√©ricos de √°ngulos
- Puntos corporales detectados
- L√≠neas que muestran la inclinaci√≥n
- C√≥digo de colores seg√∫n estado postural

### Sistema de Alertas

```python
if self.save_metrics:
    if bad_time > self.args.time_threshold:
        if self.flag_alert:
            self.sendWarning()
            raw_key = f"raw_frame:{self.session_id}"
            r.hincrby(buffer_key, "alert_count", 1)
            r.hset(raw_key, "flag_alert", "1")
            r.hset(raw_key, "bad_time", round(bad_time, 1))
            self.flag_alert = False
            self.bad_frames = 0  # Reiniciar contador
```

El sistema de alertas:
1. Se activa cuando el tiempo en mala postura excede el umbral
2. Marca el frame para an√°lisis con IA
3. Evita alertas repetidas con flag_alert
4. Reinicia el contador para la siguiente detecci√≥n

### Recolecci√≥n de M√©tricas

```python
accum = r.hgetall(buffer_key)
good_acc = int(accum.get("good_frames", 0))
bad_acc = int(accum.get("bad_frames", 0))
alert_count = int(accum.get("alert_count", 0))
transiciones_malas = int(accum.get("transiciones_malas", 0))
tiempo_sentado = float(accum.get("tiempo_sentado", 0))
tiempo_parado = float(accum.get("tiempo_parado", 0))

total = good_acc + bad_acc or 1
percentage_good = round(good_acc / total * 100, 1)
percentage_bad = round(bad_acc / total * 100, 1)

datos = {
    "actual": "menton_en_mano",
    "porcentaje_correcta": percentage_good,
    "porcentaje_incorrecta": percentage_bad,
    "transiciones_malas": transiciones_malas,
    "tiempo_sentado": tiempo_sentado,
    "tiempo_parado": tiempo_parado,
    "alertas_enviadas": alert_count,
}
```

Las m√©tricas incluyen:
- Porcentajes de tiempo en buena/mala postura
- N√∫mero de transiciones posturales
- Tiempo total sentado vs parado
- Contador de alertas generadas

### Modo Calibraci√≥n

```python
if not self.save_metrics:
    calib_key = f"calib:{self.session_id}"
    if good_time > 0:
        r.hincrbyfloat(calib_key, "good_time", round(1.0 / fps, 2))
    if bad_time > 0:
        r.hincrbyfloat(calib_key, "bad_time", round(1.0 / fps, 2))
```

En modo calibraci√≥n:
- No se guardan m√©tricas permanentes
- Se acumulan tiempos buenos/malos en Redis temporal
- Permite al usuario ajustar umbrales seg√∫n su ergonom√≠a

### M√©todo de Ejecuci√≥n Standalone

```python
def run(self):
    cap = cv2.VideoCapture(self.args.video) if self.args.video else cv2.VideoCapture(0)
    
    while True:
        success, image = cap.read()
        if not success:
            break
            
        image = self.process_frame(image)
        cv2.imshow('MediaPipe Pose', image)
        
        if cv2.waitKey(1) & 0xFF == ord('q'):
            break
    
    cap.release()
    cv2.destroyAllWindows()
```

Este m√©todo permite:
- Ejecutar el monitor independientemente para pruebas
- Procesar archivos de video o c√°mara web
- Visualizaci√≥n directa con OpenCV

---

## Capa de Datos

La capa de datos del sistema implementa un dise√±o robusto utilizando SQLAlchemy como ORM y PostgreSQL como motor de base de datos. La arquitectura separa claramente las responsabilidades entre configuraci√≥n de conexi√≥n, modelos de datos y esquemas de validaci√≥n.

### Configuraci√≥n de Base de Datos (database.py)

El m√≥dulo `database.py` establece la configuraci√≥n fundamental para la conexi√≥n y gesti√≥n de sesiones:

```python
import os
from typing import Generator
from sqlalchemy import create_engine
from sqlalchemy.orm import sessionmaker, declarative_base, Session

# URL de conexi√≥n configurable por variable de entorno
DATABASE_URL = os.getenv(
    "DATABASE_URL",
    "postgresql://user:password@postgres-service:5432/shpd_db"
)
```

#### Motor de SQLAlchemy

```python
engine = create_engine(
    DATABASE_URL,
    echo=False,    # True para debugging SQL
    future=True    # API 2.0 de SQLAlchemy
)
```

Configuraci√≥n del motor:
- **echo=False**: Desactiva el logging SQL en producci√≥n
- **future=True**: Habilita la API moderna de SQLAlchemy 2.0

#### F√°brica de Sesiones

```python
SessionLocal = sessionmaker(
    autocommit=False,
    autoflush=False,
    bind=engine
)
```

Par√°metros de sesi√≥n:
- **autocommit=False**: Control manual de transacciones
- **autoflush=False**: Evita escrituras autom√°ticas a la BD
- **bind=engine**: Asocia las sesiones al motor configurado

#### Dependencia de FastAPI

```python
def get_db() -> Generator[Session, None, None]:
    db: Session = SessionLocal()
    try:
        yield db
    finally:
        db.close()
```

Esta funci√≥n generadora:
1. Crea una nueva sesi√≥n para cada request
2. La proporciona mediante inyecci√≥n de dependencias
3. Garantiza el cierre de la sesi√≥n al finalizar

### Modelos de Datos (models.py)

Los modelos definen la estructura de las tablas en la base de datos:

#### Modelo Paciente

```python
class Paciente(Base):
    __tablename__ = "pacientes"

    id = Column(Integer, primary_key=True, index=True)
    telegram_id = Column(String, unique=True, index=True, nullable=False)
    device_id = Column(String, unique=True, index=True, nullable=False)
    nombre = Column(String, nullable=False)
    edad = Column(Integer)
    sexo = Column(String)
    diagnostico = Column(String)
```

Caracter√≠sticas del modelo:
- **id**: Clave primaria autoincremental
- **telegram_id**: Identificador √∫nico para integraci√≥n con bot
- **device_id**: Identificador del dispositivo de monitoreo
- **√çndices √∫nicos**: En telegram_id y device_id para b√∫squedas r√°pidas

#### Modelo MetricaPostural

```python
class MetricaPostural(Base):
    __tablename__ = "metricas_posturales"
    
    id = Column(UUID(as_uuid=True), primary_key=True, default=uuid.uuid4)
    sesion_id = Column(UUID(as_uuid=True), ForeignKey("sesiones.id", ondelete="CASCADE"), nullable=False)
    timestamp = Column(DateTime, nullable=False)
    datos = Column(JSONB, nullable=False)
    created_at = Column(DateTime, server_default=func.now())
```

Dise√±o del modelo:
- **UUID como PK**: Identificadores √∫nicos distribuidos
- **JSONB**: Almacenamiento flexible de m√©tricas complejas
- **CASCADE**: Eliminaci√≥n autom√°tica al borrar sesi√≥n padre
- **server_default**: Timestamp autom√°tico del servidor

#### Modelo Sesion

```python
class Sesion(Base):
    __tablename__ = "sesiones"
    
    id = Column(UUID(as_uuid=True), primary_key=True, default=uuid.uuid4)
    intervalo_segundos = Column(Integer, nullable=False)
    modo = Column(String, nullable=False)
```

Atributos:
- **intervalo_segundos**: Duraci√≥n planificada de la sesi√≥n
- **modo**: Tipo de sesi√≥n (normal, calibraci√≥n, etc.)

#### Modelo PosturaCount

```python
class PosturaCount(Base):
    __tablename__ = "postura_counts"
    
    id = Column(Integer, primary_key=True, index=True)
    session_id = Column(String, index=True, nullable=False)
    posture_label = Column(String, nullable=False)
    count = Column(Integer, default=0, nullable=False)
```

Este modelo:
- Mantiene contadores de cada tipo de postura por sesi√≥n
- Optimizado para consultas agregadas
- √çndice en session_id para agrupaciones r√°pidas

### Esquemas de Validaci√≥n (schemas.py)

Los esquemas Pydantic validan y serializan datos entre la API y la base de datos:

#### Esquemas de M√©tricas

```python
class MetricaIn(BaseModel):
    sesion_id: UUID
    timestamp: datetime
    datos: dict

class MetricaOut(MetricaIn):
    id: UUID
    created_at: datetime
    
    class Config:
        orm_mode = True
```

Caracter√≠sticas:
- **MetricaIn**: Datos de entrada sin campos autogenerados
- **MetricaOut**: Incluye campos generados por la BD
- **orm_mode**: Permite crear instancias desde objetos SQLAlchemy

#### Esquemas de Paciente

```python
class PacienteOut(BaseModel):
    id: int
    telegram_id: str
    device_id: str
    nombre: str
    edad: int
    sexo: str | None = None
    diagnostico: str | None = None

    class Config:
        orm_mode = True
```

Validaciones:
- Campos opcionales con valores por defecto None
- Tipado estricto para cada campo
- Serializaci√≥n autom√°tica de modelos ORM

#### Esquemas de Sesi√≥n

```python
class SesionIn(BaseModel):
    intervalo_segundos: int
    modo: str

class SesionOut(SesionIn):
    id: UUID
    
    class Config:
        orm_mode = True
```

Patr√≥n de herencia:
- **SesionIn**: Solo campos editables por el usuario
- **SesionOut**: Hereda de SesionIn y agrega campos generados

#### Esquemas de Conteo de Posturas

```python
class PosturaCountOut(BaseModel):
    session_id: str
    posture_label: str
    count: int
    
    class Config:
        orm_mode = True
```

### Dise√±o de la Base de Datos

#### Diagrama Entidad-Relaci√≥n

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê     ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ    Paciente     ‚îÇ     ‚îÇ     Sesion       ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§     ‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ id (PK)         ‚îÇ     ‚îÇ id (PK, UUID)    ‚îÇ
‚îÇ telegram_id     ‚îÇ     ‚îÇ intervalo_seg    ‚îÇ
‚îÇ device_id       ‚îÇ     ‚îÇ modo             ‚îÇ
‚îÇ nombre          ‚îÇ     ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
‚îÇ edad            ‚îÇ              ‚îÇ
‚îÇ sexo            ‚îÇ              ‚îÇ 1
‚îÇ diagnostico     ‚îÇ              ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò              ‚îÇ *
                        ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
                        ‚îÇ MetricaPostural  ‚îÇ
                        ‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
                        ‚îÇ id (PK, UUID)    ‚îÇ
                        ‚îÇ sesion_id (FK)   ‚îÇ
                        ‚îÇ timestamp        ‚îÇ
                        ‚îÇ datos (JSONB)    ‚îÇ
                        ‚îÇ created_at       ‚îÇ
                        ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                                 
                        ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
                        ‚îÇ  PosturaCount    ‚îÇ
                        ‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
                        ‚îÇ id (PK)          ‚îÇ
                        ‚îÇ session_id       ‚îÇ
                        ‚îÇ posture_label    ‚îÇ
                        ‚îÇ count            ‚îÇ
                        ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

### Ventajas del Dise√±o

1. **Flexibilidad**: JSONB permite evoluci√≥n del esquema sin migraciones
2. **Rendimiento**: √çndices estrat√©gicos en campos de b√∫squeda frecuente
3. **Integridad**: Claves for√°neas con acciones en cascada
4. **Escalabilidad**: UUIDs permiten sistemas distribuidos
5. **Mantenibilidad**: Separaci√≥n clara entre modelos y validaci√≥n

---

## API REST y Endpoints

El backend expone una API REST completa organizada en m√≥dulos tem√°ticos. Cada router maneja un dominio espec√≠fico del sistema, facilitando el mantenimiento y la escalabilidad.

### Router de Sesiones (sesiones.py)

El router de sesiones gestiona el ciclo de vida completo de las sesiones de monitoreo:

#### Crear Sesi√≥n

```python
@router.post("/", response_model=SesionOut)
def crear_sesion(s: SesionIn, db: Session = Depends(get_db)) -> SesionOut:
    nueva = Sesion(**s.dict())
    db.add(nueva)
    db.commit()
    db.refresh(nueva)
    # Borrar marca de sesi√≥n finalizada si existe
    if hasattr(s, 'device_id'):
        r.delete(f"ended:{s.device_id}")
    return nueva
```

**Endpoint**: `POST /sesiones/`
- **Entrada**: `SesionIn` (intervalo_segundos, modo)
- **Salida**: `SesionOut` (incluye UUID generado)
- **Funci√≥n**: Crea nueva sesi√≥n y limpia marcas previas

#### Listar Sesiones

```python
@router.get("/", response_model=List[SesionOut])
def listar_sesiones(db: Session = Depends(get_db)) -> List[SesionOut]:
    return db.query(Sesion).all()
```

**Endpoint**: `GET /sesiones/`
- **Salida**: Lista de todas las sesiones
- **Uso**: Hist√≥rico y administraci√≥n

#### Progreso de Sesi√≥n

```python
@router.get("/progress/{session_id}")
def get_session_progress(session_id: str):
    key = f"shpd-session:{session_id}"
    data = r.hgetall(key)
    start_ts = int(data.get("start_ts", 0))
    intervalo = int(data.get("intervalo_segundos", 0))
    now = int(time.time())
    elapsed = now - start_ts
    if elapsed > intervalo:
        elapsed = intervalo
    return {"intervalo_segundos": intervalo, "elapsed": elapsed}
```

**Endpoint**: `GET /sesiones/progress/{session_id}`
- **Par√°metros**: session_id (UUID)
- **Salida**: Tiempo transcurrido y duraci√≥n total
- **Funci√≥n**: Monitoreo en tiempo real del progreso

#### Finalizar Sesi√≥n

```python
@router.post("/end/{device_id}")
def finalizar_sesion(device_id: str, db: Session = Depends(get_db)):
    shpd_data = r.hgetall(f"shpd-data:{device_id}")
    session_id = shpd_data.get("session_id")
    
    if not session_id:
        return {"ok": False, "message": "No se encontr√≥ session_id"}
    
    # Verificar si ya fue finalizada
    ended_key = f"ended:{session_id}"
    if r.get(ended_key):
        return {"ok": False, "message": "Sesi√≥n ya finalizada"}
    
    # Enviar reporte y limpiar datos
    enviar_reporte_telegram(session_id, device_id, db)
    r.setex(ended_key, 3600, "1")  # Marca por 1 hora
    r.hdel(f"shpd-data:{device_id}", "session_id")
    
    return {"ok": True, "message": "Sesi√≥n finalizada"}
```

**Endpoint**: `POST /sesiones/end/{device_id}`
- **Funci√≥n**: Finaliza sesi√≥n, genera reporte y limpia datos
- **Integraci√≥n**: Env√≠a resumen por Telegram

#### Reiniciar Sesi√≥n

```python
@router.post("/reiniciar/{session_id}")
def reiniciar_sesion(session_id: str, device_id: str | None = Query(None), db: Session = Depends(get_db)):
    # Validar UUID
    try:
        uuid_obj = uuid.UUID(session_id)
    except ValueError:
        return JSONResponse(status_code=400, content={"ok": False, "message": "session_id inv√°lido"})
    
    # Limpiar todos los datos asociados
    r.delete(
        f"shpd-data:{session_id}",
        f"metricas:{session_id}",
        f"analysis:{session_id}",
        f"raw_frame:{session_id}",
        f"ended:{session_id}",
        f"timeline:{session_id}"
    )
    
    # Limpiar base de datos
    db.query(PosturaCount).filter(PosturaCount.session_id == str(uuid_obj)).delete()
    db.query(MetricaPostural).filter(MetricaPostural.sesion_id == uuid_obj).delete()
    db.commit()
    
    return {"ok": True, "message": "Sesi√≥n reiniciada"}
```

**Endpoint**: `POST /sesiones/reiniciar/{session_id}`
- **Funci√≥n**: Limpia todos los datos para comenzar de nuevo
- **Uso**: Recuperaci√≥n de errores o nueva calibraci√≥n

### Router de Pacientes (pacientes.py)

Gestiona la informaci√≥n de los pacientes monitoreados:

```python
@router.get("/{device_id}", response_model=PacienteOut)
def obtener_paciente_por_device_id(device_id: str, db: Session = Depends(get_db)):
    paciente = db.query(Paciente).filter(Paciente.device_id == device_id).first()
    if not paciente:
        raise HTTPException(status_code=404, detail="Paciente no encontrado")
    return paciente
```

**Endpoint**: `GET /pacientes/{device_id}`
- **Funci√≥n**: Obtiene datos del paciente por dispositivo
- **Uso**: Personalizaci√≥n de la experiencia

### Router de M√©tricas (metricas.py)

Proporciona acceso a las m√©tricas posturales en tiempo real:

```python
@router.get("/metricas/{sesion_id}")
def obtener_metricas(sesion_id: str):
    key = f"metricas:{sesion_id}"
    ultimas = r.lrange(key, -1, -1)  # √∫ltima m√©trica
    return json.loads(ultimas[0]) if ultimas else {}
```

**Endpoint**: `GET /metricas/{sesion_id}`
- **Salida**: √öltima m√©trica disponible
- **Contenido**:
  - porcentaje_correcta
  - porcentaje_incorrecta
  - transiciones_malas
  - tiempo_sentado/parado
  - alertas_enviadas

### Router de An√°lisis (analysis.py)

Acceso a los resultados del an√°lisis con IA:

```python
@router.get("/analysis/{sesion_id}")
def obtener_analysis(sesion_id: str):
    key = f"analysis:{sesion_id}"
    raw = r.hgetall(key)
    
    # Convertir valores a enteros
    result: dict[str, int] = {}
    for k, v in raw.items():
        try:
            result[k] = int(v)
        except ValueError:
            result[k] = int(float(v)) if v else 0
    
    return result
```

**Endpoint**: `GET /analysis/{sesion_id}`
- **Salida**: Diccionario con las 13 posturas y sus porcentajes
- **Formato**: `{"Sentado erguido": 85, "Inclinaci√≥n hacia adelante": 15, ...}`

### Router de Conteo de Posturas (postura_counts.py)

Estad√≠sticas agregadas de posturas detectadas:

```python
@router.get("/{session_id}", response_model=List[PosturaCountOut])
def obtener_postura_counts(session_id: str, db: Session = Depends(get_db)):
    resultados = (
        db.query(PosturaCount)
        .filter(PosturaCount.session_id == session_id)
        .all()
    )
    if not resultados:
        raise HTTPException(status_code=404, detail="No counts found")
    return resultados
```

**Endpoint**: `GET /postura_counts/{session_id}`
- **Salida**: Lista de posturas con sus conteos
- **Uso**: Gr√°ficos y estad√≠sticas de sesi√≥n

### Router de Timeline (timeline.py)

Historial temporal de eventos posturales:

```python
@router.get("/{session_id}")
def obtener_timeline(session_id: str):
    key = f"timeline:{session_id}"
    raw = r.lrange(key, 0, -1)
    eventos = []
    
    for item in raw:
        try:
            ev = json.loads(item)
            # Formatear timestamp
            ts = datetime.fromisoformat(ev.get("timestamp"))
            ev["timestamp"] = ts.strftime("%H:%M:%S")
            eventos.append(ev)
        except Exception:
            continue
            
    return eventos
```

**Endpoint**: `GET /timeline/{session_id}`
- **Salida**: Lista cronol√≥gica de cambios posturales
- **Formato**: `[{"timestamp": "14:30:15", "postura": "Ment√≥n en mano", "tiempo_mala_postura": 12.5}]`

### Router de Calibraci√≥n (calibracion.py)

Endpoints espec√≠ficos para el modo calibraci√≥n:

#### Progreso de Calibraci√≥n

```python
@router.get("/progress/{session_id}")
def calib_progress(session_id: str):
    data = r.hgetall(f"calib:{session_id}")
    good = float(data.get("good_time", 0))
    bad = float(data.get("bad_time", 0))
    return {
        "good_time": good,
        "bad_time": bad,
        "correcta": good > bad
    }
```

**Endpoint**: `GET /calib/progress/{session_id}`
- **Funci√≥n**: Monitorea tiempos en calibraci√≥n
- **Uso**: Ajuste de umbrales personalizados

#### Gesti√≥n de Modos

```python
@router.post("/mode/{device_id}/{mode}")
def set_mode(device_id: str, mode: str):
    if mode not in ("calib", "normal"):
        raise HTTPException(status_code=400, detail="mode must be 'calib' or 'normal'")
    
    key = f"shpd-data:{device_id}"
    r.hset(key, mapping={"mode": mode})
    return {"device_id": device_id, "mode": mode}
```

**Endpoint**: `POST /calib/mode/{device_id}/{mode}`
- **Valores**: "calib" o "normal"
- **Funci√≥n**: Cambia entre modo calibraci√≥n y normal

### Documentaci√≥n Autom√°tica

FastAPI genera documentaci√≥n interactiva autom√°ticamente:

- **Swagger UI**: Disponible en `/docs`
- **ReDoc**: Disponible en `/redoc`
- **OpenAPI Schema**: En `/openapi.json`

### Manejo de Errores

Todos los endpoints implementan manejo consistente de errores:

```python
# 400 Bad Request - Datos inv√°lidos
{"detail": "Validation error", "errors": [...]}

# 404 Not Found - Recurso no existe
{"detail": "Resource not found"}

# 500 Internal Server Error - Error del servidor
{"detail": "Internal server error"}
```

### Autenticaci√≥n y Seguridad

El sistema actual implementa:
- **CORS habilitado**: Permite acceso desde cualquier origen (desarrollo)
- **Validaci√≥n de entrada**: Mediante esquemas Pydantic
- **Inyecci√≥n SQL prevenida**: Uso de ORM con par√°metros seguros

### Mejoras de Seguridad Recomendadas

1. **Autenticaci√≥n JWT**: Para proteger endpoints sensibles
2. **Rate Limiting**: Prevenir abuso de la API
3. **CORS restrictivo**: Limitar or√≠genes en producci√≥n
4. **HTTPS obligatorio**: Encriptaci√≥n de datos en tr√°nsito
5. **API Keys**: Para integraciones externas

---

## Sistema de Comunicaci√≥n en Tiempo Real

El backend implementa comunicaci√≥n bidireccional en tiempo real mediante WebSockets, permitiendo el streaming de video y el procesamiento instant√°neo de frames.

### Arquitectura de WebSockets

El sistema utiliza dos endpoints WebSocket principales:

1. **Entrada de Video**: Recibe frames desde el cliente
2. **Salida de Video**: Transmite frames procesados

### WebSocket de Entrada

```python
@app.websocket("/video/input/{device_id}")
async def video_input(websocket: WebSocket, device_id: str):
```

#### Flujo de Procesamiento

1. **Aceptaci√≥n de Conexi√≥n**
```python
await websocket.accept()
loop = asyncio.get_running_loop()
```

2. **Detecci√≥n de Modo**
```python
calibrating_query = websocket.scope.get("query_string", b"").decode().find("calibracion=1") >= 0
await websocket.send_text(json.dumps({"type": "modo", "calibracion": calibrating_query}))
```

3. **Gesti√≥n Din√°mica de Sesiones**
```python
while True:
    redis_shpd_key = f"shpd-data:{device_id}"
    session_id = r.hget(redis_shpd_key, "session_id")
    
    if session_id != current_session_id:
        posture_monitor = PostureMonitor(session_id, save_metrics=not calibrating)
        current_session_id = session_id
```

4. **Procesamiento As√≠ncrono de Frames**
```python
data = await websocket.receive_bytes()
frame = await loop.run_in_executor(None, _decode_jpeg, data)
processed = await loop.run_in_executor(None, posture_monitor.process_frame, frame)
jpeg = await loop.run_in_executor(None, _encode_jpeg, processed)
```

### WebSocket de Salida

```python
@app.websocket("/video/output")
async def video_output(websocket: WebSocket):
    await websocket.accept()
    while True:
        jpeg = await processed_frames_queue.get()
        await websocket.send_bytes(jpeg)
```

### Gesti√≥n de Colas

El sistema utiliza colas as√≠ncronas para desacoplar el procesamiento:

```python
processed_frames_queue: asyncio.Queue = asyncio.Queue(maxsize=10)
```

Caracter√≠sticas:
- **Tama√±o limitado**: Previene desbordamiento de memoria
- **Pol√≠tica FIFO**: Frames m√°s antiguos se descartan si la cola est√° llena
- **Backpressure autom√°tico**: El productor se bloquea si la cola est√° llena

### Optimizaci√≥n de Rendimiento

1. **Procesamiento en Thread Pool**
```python
await loop.run_in_executor(None, posture_monitor.process_frame, frame)
```
- Evita bloquear el event loop
- Permite procesamiento paralelo de m√∫ltiples conexiones

2. **Compresi√≥n JPEG Adaptativa**
```python
cv2.imencode('.jpg', frame, [cv2.IMWRITE_JPEG_QUALITY, 50])
```
- Calidad 50: Balance entre calidad visual y ancho de banda
- Reduce latencia de transmisi√≥n

3. **Gesti√≥n de Desconexiones**
```python
except WebSocketDisconnect:
    logger.info(f"WebSocket desconectado para device_id: {device_id}")
```

### Protocolo de Comunicaci√≥n

#### Mensajes de Control
```json
{
    "type": "modo",
    "calibracion": true
}
```

#### Formato de Datos
- **Entrada**: Bytes JPEG raw
- **Salida**: Bytes JPEG procesados con overlays visuales

---

## Integraci√≥n con OpenAI

El sistema utiliza la API de OpenAI GPT-4 Vision para an√°lisis avanzado de posturas cuando MediaPipe detecta anomal√≠as sostenidas.

### Configuraci√≥n del Cliente

```python
API_KEY = os.getenv("OPENAI_API_KEY", "sk-proj-...")
client = OpenAI(api_key=API_KEY)
MODEL = "gpt-4o-mini"
```

### Construcci√≥n de Prompts

El sistema utiliza un prompt especializado para clasificaci√≥n de posturas:

```python
SYSTEM_PROMPT = """Eres un asistente de clasificaci√≥n de posturas basado en visi√≥n.
Cuando recibas una imagen, analiza la postura de la persona 
qu√© tan predominante es cada una de las siguientes 13 posturas al sentarse.
Las posturas son:
- Sentado erguido
- Inclinaci√≥n hacia adelante
- Inclinaci√≥n hacia atr√°s
- Inclinaci√≥n hacia la izquierda
- Inclinaci√≥n hacia la derecha
- Ment√≥n en mano
- Piernas cruzadas
- Rodillas elevadas o muy bajas
- Hombros encogidos
- Brazos sin apoyo
- Cabeza adelantada
- Encorvarse hacia adelante
- Sentarse en el borde del asiento

Determina y devuelve estrictamente un objeto JSON, sin cercos de c√≥digo circundante.
Para cada postura devuelve un porcentaje entre 0 y 100.
"""
```

### Worker de An√°lisis As√≠ncrono

```python
async def api_analysis_worker():
    loop = asyncio.get_running_loop()
    while True:
        payload = await api_analysis_queue.get()
        
        # Codificar imagen
        b64 = base64.b64encode(payload["jpeg"]).decode("utf-8")
        
        # Llamar a OpenAI
        response = await loop.run_in_executor(
            None,
            lambda: client.chat.completions.create(
                user=payload["session_id"],
                model=MODEL,
                messages=build_openai_messages(b64),
                temperature=0,
                max_tokens=500
            )
        )
```

### Procesamiento de Resultados

```python
content = response.choices[0].message.content
result: dict[str, int] = json.loads(content)

# Encontrar postura predominante
top_label, top_value = max(result.items(), key=lambda kv: kv[1])

# Actualizar base de datos
fila = db.query(PosturaCount).filter(
    PosturaCount.session_id == session_id,
    PosturaCount.posture_label == top_label
).first()

if fila:
    fila.count += 1
else:
    nueva = PosturaCount(
        session_id=session_id,
        posture_label=top_label,
        count=1
    )
    db.add(nueva)
```

### Gesti√≥n de Eventos

```python
# Guardar en timeline
evt = {
    "timestamp": datetime.utcnow().isoformat(),
    "postura": top_label,
    "tiempo_mala_postura": bad_time
}
r.rpush(f"timeline:{session_id}", json.dumps(evt))
r.ltrim(f"timeline:{session_id}", -200, -1)  # Mantener √∫ltimos 200 eventos
```

### Optimizaciones

1. **Procesamiento As√≠ncrono**: No bloquea el flujo principal
2. **Rate Limiting Impl√≠cito**: Solo se analiza cuando hay alertas
3. **Cach√© de Resultados**: Se almacenan en Redis para consulta r√°pida
4. **Modelo Optimizado**: GPT-4o-mini para balance costo/rendimiento

---

## Sistema de Cach√© con Redis

Redis act√∫a como columna vertebral para el almacenamiento temporal y la comunicaci√≥n entre componentes.

### Conexi√≥n y Configuraci√≥n

```python
r = redis.Redis(host="redis", port=6379, decode_responses=True)
```

### Estructuras de Datos Utilizadas

#### 1. Datos de Sesi√≥n (Hash)
```python
Key: shpd-data:{device_id}
Fields:
  - session_id: UUID de la sesi√≥n activa
  - mode: "normal" o "calib"
  - good_frames: Contador de frames correctos
  - bad_frames: Contador de frames incorrectos
  - transiciones_malas: Contador de cambios posturales
  - tiempo_sentado: Tiempo acumulado sentado
  - tiempo_parado: Tiempo acumulado de pie
  - alert_count: N√∫mero de alertas generadas
```

#### 2. Informaci√≥n de Sesi√≥n (Hash)
```python
Key: shpd-session:{session_id}
Fields:
  - start_ts: Timestamp de inicio (Unix)
  - intervalo_segundos: Duraci√≥n planificada
```

#### 3. M√©tricas en Tiempo Real (List)
```python
Key: metricas:{session_id}
Formato: JSON strings con estructura:
{
    "porcentaje_correcta": 75.5,
    "porcentaje_incorrecta": 24.5,
    "transiciones_malas": 5,
    "tiempo_sentado": 300.0,
    "tiempo_parado": 10.0,
    "alertas_enviadas": 2
}
```

#### 4. Resultados de An√°lisis (Hash)
```python
Key: analysis:{session_id}
Fields: Cada postura con su porcentaje
Example:
  "Sentado erguido": "85"
  "Inclinaci√≥n hacia adelante": "15"
```

#### 5. Timeline de Eventos (List)
```python
Key: timeline:{session_id}
Formato: JSON strings con estructura:
{
    "timestamp": "2024-01-15T14:30:15",
    "postura": "Ment√≥n en mano",
    "tiempo_mala_postura": 12.5
}
```

#### 6. Datos de Calibraci√≥n (Hash)
```python
Key: calib:{session_id}
Fields:
  - good_time: Tiempo acumulado en buena postura
  - bad_time: Tiempo acumulado en mala postura
```

### Operaciones Comunes

#### Incremento At√≥mico
```python
r.hincrby(buffer_key, "good_frames", 1)
r.hincrbyfloat(buffer_key, "tiempo_sentado", round(delta, 1))
```

#### Gesti√≥n de Listas con L√≠mite
```python
r.rpush(key, json.dumps(datos))
r.ltrim(key, -50, -1)  # Mantener √∫ltimos 50 elementos
```

#### TTL para Datos Temporales
```python
r.setex(ended_key, 3600, "1")  # Expira en 1 hora
```

### Ventajas del Uso de Redis

1. **Velocidad**: Acceso en microsegundos
2. **Atomicidad**: Operaciones at√≥micas para contadores
3. **Pub/Sub**: Potencial para eventos en tiempo real
4. **Persistencia Opcional**: Snapshots para recuperaci√≥n
5. **Escalabilidad**: Clustering para alta disponibilidad

---

## Despliegue y Containerizaci√≥n

El sistema est√° dise√±ado para desplegarse en entornos containerizados usando Docker y Kubernetes.

### Dockerfile

```dockerfile
FROM python:3.11-slim

ENV DEBIAN_FRONTEND=noninteractive

# Instalar dependencias del sistema
RUN apt-get update && apt-get install -y \
    libgl1-mesa-glx \    # OpenGL para OpenCV
    libglib2.0-0 \       # GLib para MediaPipe
    libsm6 \             # Session Management
    libxext6 \           # X11 extensions
    libxrender1 \        # X Rendering Extension
    ffmpeg \             # Procesamiento multimedia
    && apt-get clean && rm -rf /var/lib/apt/lists/*

WORKDIR /app

# Instalar dependencias Python
COPY requirements.txt .
RUN pip install --no-cache-dir -r requirements.txt

# Copiar c√≥digo fuente
COPY . .

CMD ["python", "main.py"]
```

### Configuraci√≥n de Kubernetes

#### Deployment del Backend
```yaml
# shpd-backend.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: shpd-backend
spec:
  replicas: 2
  selector:
    matchLabels:
      app: shpd-backend
  template:
    spec:
      containers:
      - name: backend
        image: shpd-backend:latest
        ports:
        - containerPort: 8765
        env:
        - name: DATABASE_URL
          valueFrom:
            secretKeyRef:
              name: db-credentials
              key: url
        - name: OPENAI_API_KEY
          valueFrom:
            secretKeyRef:
              name: openai-credentials
              key: api-key
```

#### Service del Backend
```yaml
# backend-svc.yaml
apiVersion: v1
kind: Service
metadata:
  name: backend-service
spec:
  selector:
    app: shpd-backend
  ports:
  - protocol: TCP
    port: 8765
    targetPort: 8765
  type: LoadBalancer
```

#### Deployment de Redis
```yaml
# redis-deploy.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: redis
spec:
  replicas: 1
  selector:
    matchLabels:
      app: redis
  template:
    spec:
      containers:
      - name: redis
        image: redis:7-alpine
        ports:
        - containerPort: 6379
        volumeMounts:
        - name: redis-storage
          mountPath: /data
```

### Variables de Entorno

```bash
# Producci√≥n
DATABASE_URL=postgresql://user:pass@postgres-service:5432/shpd_db
REDIS_URL=redis://redis-service:6379/0
OPENAI_API_KEY=sk-proj-...

# Desarrollo
DATABASE_URL=postgresql://localhost:5432/shpd_dev
REDIS_URL=redis://localhost:6379/0
```

### Pipeline de CI/CD

```yaml
# .gitlab-ci.yml ejemplo
stages:
  - build
  - test
  - deploy

build:
  stage: build
  script:
    - docker build -t $CI_REGISTRY_IMAGE:$CI_COMMIT_SHA .
    - docker push $CI_REGISTRY_IMAGE:$CI_COMMIT_SHA

test:
  stage: test
  script:
    - pip install -r requirements.txt
    - pytest tests/

deploy:
  stage: deploy
  script:
    - kubectl set image deployment/shpd-backend backend=$CI_REGISTRY_IMAGE:$CI_COMMIT_SHA
```

### Monitoreo y Logging

1. **Prometheus Metrics**: Exportar m√©tricas de rendimiento
2. **ELK Stack**: Centralizaci√≥n de logs
3. **Health Checks**: Endpoints de salud para K8s
4. **Distributed Tracing**: Jaeger para trazabilidad

### Consideraciones de Producci√≥n

1. **Escalado Horizontal**: M√∫ltiples r√©plicas del backend
2. **Load Balancing**: Distribuci√≥n de carga WebSocket
3. **SSL/TLS**: Terminaci√≥n en el ingress controller
4. **Backup**: Snapshots peri√≥dicos de PostgreSQL y Redis
5. **Secrets Management**: Kubernetes secrets o HashiCorp Vault

---

## Flujo de Datos y Casos de Uso

### Flujo General del Sistema

El sistema sigue un flujo de datos bien definido desde la captura de video hasta la generaci√≥n de reportes:

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê     ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê     ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ   Cliente   ‚îÇ‚îÄ‚îÄ‚îÄ‚îÄ‚ñ∂‚îÇ  WebSocket   ‚îÇ‚îÄ‚îÄ‚îÄ‚îÄ‚ñ∂‚îÇ PostureMonitor  ‚îÇ
‚îÇ  (C√°mara)   ‚îÇ     ‚îÇ   /input     ‚îÇ     ‚îÇ   (MediaPipe)   ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò     ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò     ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                                                   ‚îÇ
                           ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
                           ‚îÇ                                        ‚îÇ
                    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê                         ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
                    ‚îÇ   An√°lisis  ‚îÇ                         ‚îÇ    Redis    ‚îÇ
                    ‚îÇ   B√°sico    ‚îÇ                         ‚îÇ   (Cach√©)   ‚îÇ
                    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò                         ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                           ‚îÇ                                        ‚îÇ
                           ‚îÇ Si alerta                              ‚îÇ
                    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê                                ‚îÇ
                    ‚îÇ   OpenAI    ‚îÇ                                ‚îÇ
                    ‚îÇ   Worker    ‚îÇ                                ‚îÇ
                    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò                                ‚îÇ
                           ‚îÇ                                        ‚îÇ
                           ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                                           ‚îÇ
                                    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
                                    ‚îÇ PostgreSQL  ‚îÇ
                                    ‚îÇ    (BD)     ‚îÇ
                                    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                                           ‚îÇ
                    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
                    ‚îÇ                                           ‚îÇ
             ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê                            ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
             ‚îÇ  REST API   ‚îÇ                            ‚îÇ  WebSocket   ‚îÇ
             ‚îÇ  Endpoints  ‚îÇ                            ‚îÇ   /output    ‚îÇ
             ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò                            ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                    ‚îÇ                                           ‚îÇ
                    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                                   ‚îÇ
                            ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
                            ‚îÇ   Cliente   ‚îÇ
                            ‚îÇ (Frontend)  ‚îÇ
                            ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

### Casos de Uso Principales

#### 1. Sesi√≥n de Monitoreo Normal

**Actor**: Usuario final (paciente)
**Flujo**:
1. El usuario inicia sesi√≥n desde la aplicaci√≥n web
2. Se crea una nueva sesi√≥n con duraci√≥n predefinida
3. La c√°mara comienza a transmitir video v√≠a WebSocket
4. MediaPipe analiza cada frame detectando puntos clave
5. Se calculan √°ngulos posturales en tiempo real
6. Si se detecta mala postura sostenida:
   - Se genera una alerta visual
   - Se env√≠a el frame a OpenAI para an√°lisis detallado
   - Se registra el evento en la timeline
7. Al finalizar la sesi√≥n:
   - Se genera un reporte completo
   - Se env√≠a resumen por Telegram
   - Se limpian datos temporales

**C√≥digo relevante**:
```python
# Creaci√≥n de sesi√≥n
POST /sesiones/
{
    "intervalo_segundos": 1800,
    "modo": "normal"
}

# Monitoreo en tiempo real
WS /video/input/{device_id}

# Consulta de m√©tricas
GET /metricas/{session_id}

# Finalizaci√≥n
POST /sesiones/end/{device_id}
```

#### 2. Modo Calibraci√≥n

**Actor**: Usuario configurando el sistema
**Flujo**:
1. Usuario activa modo calibraci√≥n
2. Se realizan posturas de referencia
3. El sistema mide tiempos en buena/mala postura
4. Usuario ajusta umbrales seg√∫n feedback visual
5. Los nuevos umbrales se guardan para futuras sesiones

**C√≥digo relevante**:
```python
# Activar calibraci√≥n
POST /calib/mode/{device_id}/calib

# Monitorear progreso
GET /calib/progress/{session_id}

# WebSocket con query parameter
WS /video/input/{device_id}?calibracion=1
```

#### 3. An√°lisis Hist√≥rico

**Actor**: Profesional de salud
**Flujo**:
1. Accede al historial de sesiones del paciente
2. Visualiza m√©tricas agregadas por sesi√≥n
3. Revisa timeline de eventos posturales
4. Analiza tendencias en tipos de posturas
5. Genera reportes para seguimiento

**Endpoints utilizados**:
```python
# Listar sesiones
GET /sesiones/

# Obtener conteos de posturas
GET /postura_counts/{session_id}

# Ver timeline detallada
GET /timeline/{session_id}

# An√°lisis por IA
GET /analysis/{session_id}
```

#### 4. Integraci√≥n con Bot de Telegram

**Actor**: Sistema automatizado
**Flujo**:
1. Al finalizar sesi√≥n, se recopilan m√©tricas finales
2. Se consulta informaci√≥n del paciente
3. Se formatea reporte con estad√≠sticas clave
4. Se env√≠a v√≠a API al servicio del bot
5. Usuario recibe notificaci√≥n en Telegram

**Implementaci√≥n**:
```python
def enviar_reporte_telegram(session_id, device_id, db: Session):
    # Obtener datos del paciente
    paciente = db.query(Paciente).filter(
        Paciente.device_id == device_id
    ).first()
    
    # Recopilar m√©tricas
    metricas = r.lrange(f"metricas:{session_id}", 0, -1)
    ultima = json.loads(metricas[-1]) if metricas else {}
    
    # Formatear y enviar
    resumen = f"‚úÖ Reporte de sesi√≥n\n..."
    payload = {"telegram_id": paciente.telegram_id, "resumen": resumen}
    requests.post(BOT_API_URL, json=payload)
```

### Flujo de Procesamiento de Video

#### 1. Recepci√≥n de Frame
```python
data = await websocket.receive_bytes()  # JPEG comprimido
frame = cv2.imdecode(np.frombuffer(data, np.uint8), cv2.IMREAD_COLOR)
```

#### 2. Detecci√≥n de Pose
```python
image_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
keypoints = self.pose.process(image_rgb)  # MediaPipe
```

#### 3. C√°lculo de M√©tricas
```python
neck_angle = self.findAngle(shoulder_x, shoulder_y, ear_x, ear_y)
torso_angle = self.findAngle(hip_x, hip_y, shoulder_x, shoulder_y)
```

#### 4. Evaluaci√≥n y Visualizaci√≥n
```python
if neck_angle < threshold and torso_angle < threshold:
    # Postura correcta - visualizaci√≥n verde
else:
    # Postura incorrecta - visualizaci√≥n roja
    # Posible disparo de an√°lisis con IA
```

#### 5. Transmisi√≥n de Resultado
```python
processed_jpeg = cv2.imencode('.jpg', processed_frame)[1].tobytes()
await processed_frames_queue.put(processed_jpeg)
```

### Gesti√≥n de Estados

El sistema mantiene varios estados concurrentes:

1. **Estado de Sesi√≥n**: Activa, pausada, finalizada
2. **Estado de Calibraci√≥n**: Normal o calibraci√≥n
3. **Estado de Alerta**: Pendiente o enviada
4. **Estado de Conexi√≥n**: Conectado o desconectado

Estos estados se gestionan principalmente en Redis para acceso r√°pido y consistente entre componentes.

---

## An√°lisis de Fortalezas y Oportunidades de Mejora

### Fortalezas del Dise√±o Actual

#### 1. Arquitectura As√≠ncrona
- **Ventaja**: Alta concurrencia sin bloqueos
- **Implementaci√≥n**: FastAPI + asyncio permiten manejar m√∫ltiples streams simult√°neos
- **Beneficio**: Escalabilidad vertical eficiente

#### 2. Procesamiento en Tiempo Real
- **Ventaja**: Feedback inmediato al usuario
- **Implementaci√≥n**: MediaPipe optimizado + WebSockets
- **Beneficio**: Experiencia de usuario fluida

#### 3. Integraci√≥n de IA Inteligente
- **Ventaja**: An√°lisis detallado solo cuando es necesario
- **Implementaci√≥n**: Disparadores basados en umbrales
- **Beneficio**: Optimizaci√≥n de costos de API

#### 4. Persistencia H√≠brida
- **Ventaja**: Balance entre velocidad y durabilidad
- **Implementaci√≥n**: Redis para tiempo real + PostgreSQL para hist√≥ricos
- **Beneficio**: Rendimiento √≥ptimo sin perder datos

#### 5. Modularidad del C√≥digo
- **Ventaja**: F√°cil mantenimiento y extensi√≥n
- **Implementaci√≥n**: Routers separados por dominio
- **Beneficio**: Desarrollo paralelo de features

#### 6. Containerizaci√≥n Completa
- **Ventaja**: Despliegue consistente
- **Implementaci√≥n**: Docker + Kubernetes
- **Beneficio**: DevOps simplificado

### Oportunidades de Mejora

#### 1. Sistema de Autenticaci√≥n
**Situaci√≥n Actual**: Sin autenticaci√≥n implementada
**Propuesta**:
```python
# Implementar JWT con FastAPI-Users
from fastapi_users import FastAPIUsers
from fastapi_users.authentication import JWTAuthentication

auth_backend = JWTAuthentication(secret=SECRET, lifetime_seconds=3600)
```

#### 2. Optimizaci√≥n de An√°lisis con IA
**Situaci√≥n Actual**: Una imagen por alerta
**Propuesta**:
- Implementar batching de im√°genes
- An√°lisis de secuencias temporales
- Cache de resultados similares

#### 3. Escalabilidad de WebSockets
**Situaci√≥n Actual**: Single-instance queue
**Propuesta**:
```python
# Implementar Redis Pub/Sub para multi-instancia
async def video_input_scalable(websocket: WebSocket, device_id: str):
    channel = f"frames:{device_id}"
    pubsub = r.pubsub()
    await pubsub.subscribe(channel)
```

#### 4. M√©tricas de Sistema
**Situaci√≥n Actual**: Logging b√°sico
**Propuesta**:
```python
# Integrar Prometheus
from prometheus_client import Counter, Histogram, Gauge

frames_processed = Counter('frames_processed_total', 'Total frames processed')
processing_time = Histogram('frame_processing_seconds', 'Time to process frame')
active_sessions = Gauge('active_sessions', 'Number of active sessions')
```

#### 5. Validaci√≥n de Datos Mejorada
**Situaci√≥n Actual**: Validaci√≥n b√°sica con Pydantic
**Propuesta**:
```python
# Esquemas m√°s estrictos
class MetricaIn(BaseModel):
    sesion_id: UUID
    timestamp: datetime
    datos: dict
    
    @validator('datos')
    def validate_datos(cls, v):
        required_keys = ['porcentaje_correcta', 'porcentaje_incorrecta']
        if not all(k in v for k in required_keys):
            raise ValueError('Faltan campos requeridos')
        return v
```

#### 6. Tests Automatizados
**Situaci√≥n Actual**: Sin tests visibles
**Propuesta**:
```python
# tests/test_posture_monitor.py
import pytest
from posture_monitor import PostureMonitor

@pytest.fixture
def monitor():
    return PostureMonitor("test-session", save_metrics=False)

def test_angle_calculation(monitor):
    angle = monitor.findAngle(0, 0, 1, 1)
    assert 40 < angle < 50  # ~45 grados
```

#### 7. Gesti√≥n de Configuraci√≥n
**Situaci√≥n Actual**: Variables hardcodeadas
**Propuesta**:
```python
# config.py
from pydantic import BaseSettings

class Settings(BaseSettings):
    database_url: str
    redis_url: str
    openai_api_key: str
    jwt_secret: str
    
    class Config:
        env_file = ".env"

settings = Settings()
```

#### 8. Documentaci√≥n de API Mejorada
**Situaci√≥n Actual**: Documentaci√≥n autom√°tica b√°sica
**Propuesta**:
```python
@router.post("/sesiones/", 
    response_model=SesionOut,
    summary="Crear nueva sesi√≥n",
    description="""
    Crea una nueva sesi√≥n de monitoreo postural.
    
    La sesi√≥n incluye:
    - Duraci√≥n en segundos
    - Modo de operaci√≥n (normal/calibraci√≥n)
    - UUID √∫nico generado autom√°ticamente
    """,
    response_description="Sesi√≥n creada exitosamente"
)
```

### Matriz de Priorizaci√≥n

| Mejora | Impacto | Esfuerzo | Prioridad |
|--------|---------|----------|-----------|
| Autenticaci√≥n | Alto | Medio | 1 |
| Tests | Alto | Bajo | 2 |
| Configuraci√≥n | Medio | Bajo | 3 |
| M√©tricas | Medio | Medio | 4 |
| Escalabilidad WS | Bajo | Alto | 5 |

---

## Conclusiones

### Logros del Proyecto

El backend desarrollado para el sistema de detecci√≥n de posturas representa una soluci√≥n integral y moderna que cumple exitosamente con los objetivos planteados:

1. **Procesamiento en Tiempo Real**: La implementaci√≥n con MediaPipe y WebSockets permite an√°lisis instant√°neo de posturas con latencia m√≠nima.

2. **Inteligencia Artificial Aplicada**: La integraci√≥n con OpenAI GPT-4 Vision proporciona an√°lisis detallado de 13 tipos diferentes de posturas, superando las capacidades de sistemas tradicionales.

3. **Arquitectura Escalable**: El dise√±o basado en microservicios con FastAPI, Redis y PostgreSQL permite crecer horizontalmente seg√∫n la demanda.

4. **Experiencia de Usuario Optimizada**: El feedback visual inmediato y las alertas inteligentes crean una experiencia fluida y educativa.

5. **Integraci√≥n Multiplataforma**: El soporte para web y Telegram ampl√≠a el alcance y la utilidad del sistema.

### Contribuciones T√©cnicas

#### 1. Patr√≥n de Procesamiento H√≠brido
La combinaci√≥n de an√°lisis local (MediaPipe) con an√°lisis en la nube (OpenAI) establece un nuevo paradigma de eficiencia:
- Procesamiento r√°pido para detecci√≥n b√°sica
- An√°lisis profundo solo cuando es necesario
- Optimizaci√≥n de costos sin sacrificar funcionalidad

#### 2. Gesti√≥n de Estado Distribuido
El uso de Redis como "source of truth" temporal demuestra c√≥mo manejar estado en aplicaciones distribuidas:
- Sincronizaci√≥n entre componentes sin acoplamiento
- Recuperaci√≥n ante fallos
- M√©tricas en tiempo real sin impacto en rendimiento

#### 3. Pipeline de Video As√≠ncrono
La implementaci√≥n de WebSockets con procesamiento as√≠ncrono establece mejores pr√°cticas para aplicaciones de video:
- Sin bloqueos en el event loop
- Gesti√≥n eficiente de backpressure
- Escalabilidad natural

### Impacto en Salud Postural

Este sistema tiene el potencial de:
1. **Prevenir lesiones**: Detecci√≥n temprana de malas posturas
2. **Educar usuarios**: Feedback visual para crear conciencia
3. **Facilitar seguimiento m√©dico**: Datos objetivos para profesionales
4. **Personalizar tratamientos**: Calibraci√≥n individual de umbrales

### Direcciones Futuras

#### Corto Plazo (3-6 meses)
1. Implementar sistema de autenticaci√≥n robusto
2. Agregar suite completa de tests
3. Mejorar documentaci√≥n para desarrolladores
4. Optimizar algoritmos de detecci√≥n

#### Mediano Plazo (6-12 meses)
1. Desarrollar modelos de ML propios para reducir dependencia de APIs externas
2. Implementar an√°lisis predictivo de problemas posturales
3. A√±adir soporte para m√∫ltiples c√°maras
4. Crear dashboard anal√≠tico avanzado

#### Largo Plazo (12+ meses)
1. Expandir a detecci√≥n de ejercicios y rehabilitaci√≥n
2. Integrar con dispositivos IoT y wearables
3. Desarrollar versi√≥n m√≥vil nativa
4. Establecer plataforma SaaS completa

### Reflexi√≥n Final

El desarrollo de este backend demuestra c√≥mo las tecnolog√≠as modernas pueden combinarse para crear soluciones que impacten positivamente en la salud de las personas. La arquitectura implementada no solo resuelve el problema inmediato de detecci√≥n de posturas, sino que establece una base s√≥lida para futuras innovaciones en el campo de la salud digital.

La combinaci√≥n de procesamiento en tiempo real, inteligencia artificial, y dise√±o centrado en el usuario crea un sistema que es tanto t√©cnicamente robusto como pr√°cticamente √∫til. Este proyecto sirve como ejemplo de c√≥mo la ingenier√≠a de software puede contribuir directamente al bienestar humano, estableciendo un puente entre la tecnolog√≠a avanzada y las necesidades cotidianas de salud.

El c√≥digo fuente completo, junto con esta documentaci√≥n, proporciona no solo una soluci√≥n funcional, sino tambi√©n un recurso educativo para futuros desarrolladores interesados en aplicaciones de salud digital, procesamiento de video en tiempo real, y arquitecturas de microservicios modernas.

---

*Fin del documento*